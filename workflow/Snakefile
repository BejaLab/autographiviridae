from pandas import read_excel, read_csv
import warnings

configfile: "config.yaml"

databases = config["databases"]
genomes ,= glob_wildcards("input/genomes/{acc}.fna")
ref_contigs ,= glob_wildcards("input/ref_contigs/{acc}.fna")
fragments ,= glob_wildcards("input/genomes_pol/{acc}.faa")

sras ,= glob_wildcards("fastq/GOV2/{sra}_1.fastq.gz")

include: 'Picocyanobacteria.snakefile'
include: 'NblAs.snakefile'
include: 'Gene_predict.snakefile'

with warnings.catch_warnings(record=True):
    warnings.simplefilter("always")
    phages = read_excel("input/phages.xlsx")

rule all:
    input:
        "output/phylophlan_markers9_all.svg",
        "output/phylophlan_markers9_ref.svg",
        "output/nbla_markers9.svg",
        "output/GOV2_SRF.svg"

rule plot_gene_tree:
    input:
        tree = "analysis/phylophlan_markers7/tmp/gene_tree1/{gene}.tre.treefile",
        refs = "input/phages.xlsx",
        imgvr = "analysis/exonuclease/IMGVR_metadata.csv",
        clusters = "input/host_clusters.xlsx",
        strains = "input/host_strains.xlsx",
        exo_nbla = expand("analysis/exonuclease/{database}.gff", database = list(databases) + [ 'ref_genomes' ]),
        genome_nbla = "analysis/genomes/all_genomes_nblA.jsonl"
    output:
        plot_all = "output/gene_{gene}_all.pdf",
        plot_ref = "output/gene_{gene}_ref.pdf",
        jtree = "output/gene_{gene}.jtree"
    params:
        nbla_min_score = config["nblA"]["threshold"],
        w_all = config["phylogeny"]["w_all"],
        h_all = config["phylogeny"]["h_all"],
        w_ref = config["phylogeny"]["w_ref"],
        h_ref = config["phylogeny"]["h_ref"],
        max_mrca_dist = config["phylogeny"]["max_mrca_dist"]
    conda:
        "envs/r.yaml"
    script:
        "scripts/plot_tree.R"

rule split_contigs:
    input:
        "analysis/contigs/{database}.fna"
    output:
        directory("analysis/contigs/{database}_split")
    conda:
        "envs/search.yaml"
    shell:
        "seqkit split -i --id-regexp '(\\w+)' --by-id-prefix '' -O {output} {input}"

rule drep:
    input:
        expand("analysis/contigs/{database}_split", database = databases)
    output:
        outdir = directory("analysis/contigs/drep"),
        contigs = directory("analysis/contigs/drep/dereplicated_genomes")
    params:
        files = lambda w, input: [ d + '/*' for d in input ],
        length = config["dRep"]["length"],
        ident = config["dRep"]["identity"]
    conda:
        "envs/drep.yaml"
    threads:
        workflow.cores
    shell:
        "dRep dereplicate {output.outdir} -p {threads} -g {params.files} -l {params.length} -sa {params.ident} --S_algorithm ANImf --ignoreGenomeQuality"

rule cat_genomes:
    input:
        contigs = "analysis/contigs/drep/dereplicated_genomes",
        refs = "input/genomes",
        outliers = "input/outliers.txt"
    output:
        "analysis/genomes/all_genomes.fna"
    conda:
        "envs/search.yaml"
    shell:
        "seqkit rmdup -s {input.refs}/*.fna {input.contigs}/*.fna | seqkit grep -vf {input.outliers} -o {output}"

rule prodigal:
    input:
        "analysis/genomes/all_genomes.fna"
    output:
        faa = "analysis/genomes/all_genomes.faa",
        cds = "analysis/genomes/all_genomes.cds",
        gff = "analysis/genomes/all_genomes.gff"
    shadow:
        "minimal"
    conda:
        "envs/prodigal.yaml"
    shell:
        "prodigal -i {input} -a {output.faa} -d {output.cds} -f gff -o {output.gff}"

rule split_all_faa:
    input:
        "analysis/genomes/all_genomes.faa"
    output:
        directory("analysis/phylophlan")
    conda:
        "envs/search.yaml"
    shell:
        "seqkit split -i --id-regexp '(\\w+)_\\d+' --by-id-prefix '' -O {output} {input}"

rule select_ref_faa:
    input:
        faa = "analysis/genomes/all_genomes.faa",
        fna = expand("input/genomes/{acc}.fna", acc = genomes)
    output:
        "analysis/genomes/ref_genomes.faa"
    conda:
        "envs/search.yaml"
    shell:
        "seqkit seq -ni {input.fna} | sed -E -e 's/$/_[0-9]+$/' -e 's/^/^/' | seqkit grep -rf- {input.faa} -o {output}"

rule split_ref_faa:
    input:
        "analysis/genomes/ref_genomes.faa"
    output:
        directory("analysis/phylophlan_ref")
    conda:
        "envs/search.yaml"
    shell:
        "seqkit split -i --id-regexp '(\\w+)_\\d+' --by-id-prefix '' -O {output} {input}"

rule phylophlan_markers:
    input:
        "input/{set}.faa"
    output:
        "analysis/{set}/markers.faa"
    params:
        out_dir = "analysis/{set}",
        name = "markers"
    conda:
        "envs/phylophlan.yaml"
    shell:
        "phylophlan_setup_database -i {input} -o {params.out_dir} -d {params.name} -t a"

rule phylophlan_marker_mods:
    input:
        "input/{set}.faa"
    output:
        "analysis/{set}/markers.tsv"
    params:
        model = config["phylophlan"]["model"]
    conda:
        "envs/search.yaml"
    shell:
        "seqkit seq -ni {input} | sed 's/$/\t{params.model}/' > {output}"

rule phylophlan:
    input:
        markers = "analysis/{set}/markers.faa",
        work_dir = "analysis/phylophlan",
        cfg = "input/phylophlan_concat.cfg",
        maas = "analysis/{set}/markers.tsv"
    output:
        "analysis/phylophlan_{set}/phylophlan.tre.treefile",
        "analysis/phylophlan_{set}/tmp/msas/exonuc.aln",
        directory("analysis/phylophlan_{set}")
    params:
        min_markers = lambda w: config["phylophlan"]["min_markers"][w.set]
    conda:
        "envs/phylophlan.yaml"
    threads:
        4
    shell:
        "phylophlan -i {input.work_dir} -t a -f {input.cfg} --diversity high --trim gap_trim --subsample full --min_num_markers {params.min_markers} -d {wildcards.set} --nproc {threads} --output_folder analysis --verbose --maas {input.maas} --databases_folder analysis"

rule makeblastdb_genomes:
    input:
        "input/genomes"
    output:
        "analysis/genomes/ref_genomes.fna.ndb"
    params:
        db = "analysis/genomes/ref_genomes.fna"
    conda:
        "envs/blast.yaml"
    shell:
        "cat {input}/* | makeblastdb -in - -dbtype nucl -out {params.db} -parse_seqids -title genomes"

def blast_db(wildcards):
    if wildcards.database == 'ref_genomes':
        return "analysis/genomes/ref_genomes.fna"
    else:
        return "databases/{database}/{prefix}".format(database = wildcards.database, prefix = databases[wildcards.database])

rule tblastn:
    input:
        query = "input/exonuclease.faa",
        ndb = lambda w: blast_db(w) + '.ndb'
    output:
        "analysis/exonuclease/{database}.outfmt6"
    params:
        db = blast_db
    conda:
        "envs/blast.yaml"
    threads:
        20
    shell:
        "tblastn -db {params.db} -query {input.query} -outfmt 6 -out {output} -num_threads {threads} -max_target_seqs 100000000"

rule tblastn_to_bed:
    input:
        "analysis/exonuclease/{database}.outfmt6"
    output:
        "analysis/exonuclease/{database}.bed"
    conda:
        "envs/python.yaml"
    script:
        "scripts/outfmt6_to_bed.py"

rule filter_tblastn:
    input:
        "analysis/exonuclease/{database}.bed"
    output:
        "analysis/exonuclease/{database}.bed.merge"
    params:
        min_len   = config["exonuclease"]["length"],
        min_score = config["exonuclease"]["score"],
        min_ident = config["exonuclease"]["identity"]
    conda:
        "envs/bedtools.yaml"
    shell:
        "awk -vI={params.min_ident} '$7>=I' {input} | sort -k1,1 -k2,2n | bedtools merge -s -i - -d 7 -c 4,5,6,5,7 -o collapse,max,distinct,collapse,collapse | awk -vL={params.min_len} -vS={params.min_score} '$3-$2>=L && $5>=S' > {output}"

rule extract_exo_contigs:
    input:
         bed = "analysis/exonuclease/{database}.bed.merge",
         ndb = lambda w: blast_db(w) + '.ndb'
    output:
        "analysis/exonuclease/{database}_contigs.fna"
    params:
        db = blast_db
    conda:
        "envs/blast.yaml"
    shell:
        "cut -f1 {input.bed} | sort -u | blastdbcmd -db {params.db} -entry_batch - > {output}"

rule contigs_with_exonuclease:
    input:
        regions = "analysis/exonuclease/{database}_regions.fna",
        bed = "analysis/exonuclease/{database}.bed.merge",
        fna = "analysis/exonuclease/{database}_contigs.fna",
    output:
        "analysis/contigs/{database}.fna"
    conda:
        "envs/search.yaml"
    shell:
        "seqkit seq -ni {input.regions} | seqkit grep -f- {input.fna} -o {output}"

rule fasta_lens:
    input:
        "{prefix}.fna"
    output:
        "{prefix}.fna.lens"
    conda:
        "envs/search.yaml"
    shell:
        "seqkit fx2tab -nil -o {output} {input}"

rule extract_exo_regions:
    input:
        bed = "analysis/exonuclease/{database}.bed.merge",
        fna = "analysis/exonuclease/{database}_contigs.fna"
    output:
        "analysis/exonuclease/{database}_regions.fna"
    params:
        max_upstream   = config["recruitment"]["padding"],
        min_downstream = config["exonuclease"]["min_downstream"],
        max_downstream = config["exonuclease"]["max_downstream"]
    conda:
        "envs/python.yaml"
    script:
        "scripts/extract_region.py"

rule hmmsearch_nbla_all:
    input:
        hmm = "analysis/profile/nblA.hmm",
        fna = "analysis/exonuclease/{database}_regions.fna"
    output:
        "analysis/exonuclease/{database}_nblA.txt"
    conda:
        "envs/search.yaml"
    shell:
        "getorf -filter -find 0 {input.fna} | hmmsearch --max --cpu 1 -o {output} {input.hmm} -"

rule hmmsearch_nbla_genomes:
    input:
        hmm = "analysis/profile/nblA.hmm",
        fna = "analysis/genomes/all_genomes.fna"
    output:
        "analysis/genomes/all_genomes_nblA.txt"
    conda:
        "envs/search.yaml"
    shell:
        "getorf -filter -find 0 {input.fna} | hmmsearch --max --cpu 1 -o {output} {input.hmm} -"

rule hmmsearch_genomes:
    input:
        hmm = "analysis/profile/{profile}.hmm",
        fna = "analysis/genomes/all_genomes.fna"
    output:
        "analysis/genomes/all_genomes_profile/{profile}.txt"
    conda:
        "envs/search.yaml"
    shell:
        "getorf -filter -find 0 {input.fna} | hmmsearch --cut_nc --cpu 1 -o /dev/null --tblout {output} {input.hmm} -"

rule hmmsearch_genomes_proteins:
    input:
        jsonl = "analysis/genomes/all_genomes_nblA.jsonl",
        fna = "analysis/genomes/all_genomes.fna"
    output:
        "analysis/genomes/all_genomes_nblA.faa"
    conda:
        "envs/python.yaml"
    script:
        "scripts/extract_proteins.py"

rule parse_hmmsearch_all:
    input:
        "analysis/exonuclease/{database}_nblA.txt"
    output:
        "analysis/exonuclease/{database}_nblA.jsonl"
    params:
        threshold = config["nblA"]["threshold"]
    conda:
        "envs/python.yaml"
    script:
        "scripts/parse_hmmsearch.py"

rule parse_hmmsearch_genomes:
    input:
        "analysis/genomes/all_genomes_nblA.txt"
    output:
        "analysis/genomes/all_genomes_nblA.jsonl"
    params:
        threshold = config["nblA"]["threshold"]
    conda:
        "envs/python.yaml"
    script:
        "scripts/parse_hmmsearch.py"

rule exo_copy:
    input:
        "analysis/phylophlan_markers9/tmp/msas/exonuc.aln"
    output:
        "analysis/exonuclease/database.faa"
    conda:
        "envs/search.yaml"
    shell:
        "seqkit seq -g -o {output} {input}"

rule makeblastdb_exo:
    input:
        "analysis/exonuclease/database.faa"
    output:
        "analysis/exonuclease/database.faa.pdb"
    conda:
        "envs/search.yaml"
    shell:
        "makeblastdb -in {input} -dbtype prot"

rule exo_reciprocal_blast:
    input:
        query = "analysis/exonuclease/{database}_regions.fna",
        db = "analysis/exonuclease/database.faa",
        pdb = "analysis/exonuclease/database.faa.pdb"
    output:
        "analysis/exonuclease/{database}_regions.outfmt6"
    conda:
        "envs/search.yaml"
    threads:
        10
    shell:
        "blastx -query {input.query} -db {input.db} -out {output} -outfmt 6 -num_threads {threads}"

rule regions_with_nbla:
    input:
        fasta = "analysis/exonuclease/{database}_regions.fna",
        bed = "analysis/exonuclease/{database}.bed.merge",
        jsonl  = "analysis/exonuclease/{database}_nblA.jsonl"
    output:
        "analysis/exonuclease/{database}.gff"
    conda:
        "envs/python.yaml"
    script:
        "scripts/regions_with_nbla.py"

rule faidx:
    input:
        "{prefix}"
    output:
        "{prefix}.fai"
    conda:
        "envs/search.yaml"
    shell:
        "seqkit faidx {input}"

rule regions_for_recruitment:
    input:
        lens = "analysis/exonuclease/{database}_regions.fna.lens",
        fna = "analysis/exonuclease/{database}_regions.fna",
        fai = "analysis/exonuclease/{database}_regions.fna.fai",
        gff = "analysis/exonuclease/{database}.gff"
    output:
        "analysis/recruitment/{database}_redundant.fna"
    conda:
        "envs/bedtools.yaml"
    params:
        pad = config["recruitment"]["padding"]
    shell:
        "sort -k1,1 -k4,4n {input.gff} | bedtools merge -d 100000000 | bedtools slop -b {params.pad} -g {input.lens} | bedtools getfasta -fi {input.fna} -bed - | cut -f1 -d: > {output}"

rule cluster_regions_for_recruitment:
    input:
        "analysis/recruitment/{database}_redundant.fna"
    output:
        "analysis/recruitment/{database}.fasta"
    conda:
        "envs/cdhit.yaml"
    params:
        c = config["recruitment"]["clustering"]
    shell:
        "cd-hit -d 0 -c {params.c} -i {input} -o {output}"

rule gtf_regions_for_recruitment:
    input:
        fasta = "analysis/recruitment/{database}.fasta",
        blast = "analysis/exonuclease/{database}_regions.outfmt6",
        gff = "analysis/exonuclease/{database}.gff",
        jtree = "output/phylophlan_markers9.jtree"
    output:
        "analysis/recruitment/{database}.saf"
    params:
        identity = config["exonuclease"]["identity_for_assignment"]
    conda:
        "envs/python.yaml"
    script:
        "scripts/categorize_regions.py"

rule bwa_index:
    input:
        "{prefix}"
    output:
        "{prefix}.bwt"
    conda:
        "envs/bwa.yaml"
    shell:
        "bwa index {input}"

rule bwa_mem:
    input:
        fna = "analysis/recruitment/GOV2.fasta",
        bwa = "analysis/recruitment/GOV2.fasta.bwt",
        fq1 = "fastq/GOV2/{sra}_1.fastq.gz",
        fq2 = "fastq/GOV2/{sra}_2.fastq.gz"
    output:
        "analysis/recruitment/GOV2/bwa/{sra}.bam"
    log:
        "analysis/recruitment/GOV2/bwa/{sra}.bam.log"
    conda:
        "envs/bwa.yaml"
    shell:
        "(bwa mem {input.fna} {input.fq1} {input.fq2} | samtools view -F4 -bS - | samtools sort -o {output}) 2> {log}"

rule feature_counts:
    input:
        bam = "analysis/recruitment/GOV2/bwa/{sra}.bam",
        saf = "analysis/recruitment/GOV2.saf",
        fasta = "analysis/recruitment/GOV2.fasta"
    output:
        "analysis/recruitment/GOV2/bwa/{sra}.txt"
    conda:
        "envs/subread.yaml"
    shell:
        "featureCounts -p --countReadPairs --fraction -M -F SAF -a {input.saf} -o {output} {input.bam}"

rule gov2_dload_metadata:
    output:
        "analysis/recruitment/GOV2/metadata.xlsx"
    params:
        url = "https://ars.els-cdn.com/content/image/1-s2.0-S0092867419303411-mmc3.xlsx"
    shell:
        "wget -O {output} {params.url}"

rule plot_gov2:
    input:
        txt = expand("analysis/recruitment/GOV2/bwa/{sra}.txt", sra = sras),
        stat = expand("fastq/GOV2/{sra}_1.fastq.stat", sra = sras),
        metadata = "analysis/recruitment/GOV2/metadata.xlsx",
        jtree = "output/phylophlan_markers9.jtree",
        shp = "analysis/maps/land/ne_110m_land.shp"
    output:
        srf = "output/GOV2_SRF.svg",
        dcm = "output/GOV2_DCM.svg",
        pies = "output/GOV2_pies.svg",
        pie_data = "output/GOV2_pies.csv"
    params:
        sras = sras,
        colors = config["colors"]
    conda:
        "envs/r_plot_map.yaml"
    script:
        "scripts/plot_gov2.R"

rule imgvr_metadata:
    input:
        bed = "analysis/exonuclease/IMGVR.bed.merge",
        tsv = "databases/IMGVR/IMGVR_all_Sequence_information-high_confidence.tsv"
    output:
        "analysis/exonuclease/IMGVR_metadata.csv"
    conda:
        "envs/search.yaml"
    shell:
        "cut -f1 {input.bed} | sed -E 's/_1$//' | csvgrep -t -f- -c UVIG {input.tsv} > {output}"

rule isolated_genes_query:
    input:
        "input/isolated_genes.xlsx"
    output:
        "analysis/isolated_genes/genes.fna"
    conda:
        "envs/python.yaml"
    script:
        "scripts/isolated_genes.py"

rule makeblast:
    input:
        "analysis/isolated_genes/genes.fna"
    output:
        "analysis/isolated_genes/genes.fna.ndb"
    conda:
        "envs/blast.yaml"
    shell:
        "makeblastdb -in {input} -dbtype nucl"

rule isolated_genes_search:
    input:
        db = "analysis/isolated_genes/genes.fna",
        ndb = "analysis/isolated_genes/genes.fna.ndb",
        query = "analysis/genomes/all_genomes.fna"
    output:
        "analysis/contigs/{database}_isolated_genes.outfmt6"
    params:
        cols = 'qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore stitle'
    conda:
        "envs/phylophlan.yaml"
    shell:
        "blastn -query {input.query} -db {input.db} -out {output} -outfmt '6 {params.cols}'"

rule pol_copy:
    input:
        "input/pol_STIP37.faa"
    output:
        "analysis/pol/pol.faa"
    shell:
        "cp {input} {output}"

rule pol_makeblast:
    input:
        "analysis/pol/pol.faa"
    output:
        "analysis/pol/pol.faa.pdb"
    conda:
        "envs/search.yaml"
    shell:
        "makeblastdb -in {input} -dbtype prot"

rule search_pol:
    input:
        pol = "analysis/pol/pol.faa",
        pol_pdb = "analysis/pol/pol.faa.pdb",
        fna = "analysis/genomes/all_genomes.fna"
    output:
        "analysis/genomes/all_genomes_pol.txt"
    params:
        evalue = 1e-10,
        minsize = 99
    conda:
        "envs/search.yaml"
    threads:
        20
    shell:
        "getorf -minsize {params.minsize} -find 0 -filter {input.fna} | blastp -num_threads {threads} -query - -db {input.pol} -out {output} -outfmt 6 -evalue {params.evalue}"

rule plot_tree:
    input:
        tree = "analysis/phylophlan_{set}/phylophlan.tre.treefile",
        refs = "input/phages.xlsx",
        imgvr = "analysis/exonuclease/IMGVR_metadata.csv",
        clusters = "input/host_clusters.xlsx",
        strains = "input/host_strains.xlsx",
        exo_nbla = expand("analysis/exonuclease/{database}.gff", database = list(databases) + [ 'ref_genomes' ]),
        genome_nbla = "analysis/genomes/all_genomes_nblA.jsonl",
        psba = "analysis/genomes/all_genomes_profile/TIGR01151.1.txt",
        pol = "analysis/genomes/all_genomes_pol.txt"
    output:
        plot_all = "output/phylophlan_{set}_all.svg",
        plot_ref = "output/phylophlan_{set}_ref.svg",
        jtree = "output/phylophlan_{set}.jtree"
    params:
        nbla_min_score = config["nblA"]["threshold"],
        w_all = config["phylogeny"]["w_all"],
        h_all = config["phylogeny"]["h_all"],
        w_ref = config["phylogeny"]["w_ref"],
        h_ref = config["phylogeny"]["h_ref"],
        max_mrca_dist = config["phylogeny"]["max_mrca_dist"],
        pol_domain = "pol_pol",
        exo_domain = "pol_exo"
    conda:
        "envs/r.yaml"
    script:
        "scripts/plot_tree.R"

rule nbla_select_genomes:
    input:
        "analysis/phylophlan_{set}/phylophlan.tre.treefile"
    output:
        "analysis/nbla/genomes_{set}.txt"
    conda:
        "envs/newick_utils.yaml"
    shell:
        "nw_labels -I {input} | sed 's/$/_/' > {output}"

rule nbla_select:
    input:
        txt = "analysis/nbla/genomes_{set}.txt",
        faa = "analysis/genomes/all_genomes_nblA.faa"
    output:
        "analysis/nbla/nblA_{set}.faa"
    wildcard_constraints:
        set = '|'.join(config["phylophlan"]["min_markers"])
    conda:
        "envs/search.yaml"
    shell:
        "seqkit grep -o {output} -rf {input.txt} {input.faa}"

rule dload_map:
    output:
        "analysis/maps/land/ne_110m_land.shp"
    params:
        url = "https://www.naturalearthdata.com/http//www.naturalearthdata.com/download/110m/physical/ne_110m_land.zip"
    shadow:
        "minimal"
    shell:
        "wget -O tmp.zip '{params.url}' && unzip tmp.zip -d $(dirname {output})"
